{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using time and logging (more convenient than print statements), so be sure to run this cell before proceeding .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, logging   \n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    format='%(asctime)s.%(msecs)03d (%(threadName)s) %(message)s',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency\n",
    "## Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic setup for running a function in another thread. Notice that execution in the main program continues immediately after t.start(). Notice the difference when uncommenting the t.join(): t.join() forces the main thread to to wait for the t thread to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:07:13.274 (Thread-7) In\n",
      "17:07:13.277 (MainThread) Started\n",
      "17:07:13.279 (MainThread) Joined ..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out\n"
     ]
    }
   ],
   "source": [
    "import threading, time\n",
    "def foo():\n",
    "    logging.debug('In')\n",
    "    time.sleep(0.1)\n",
    "    print('Out')\n",
    "    \n",
    "t = threading.Thread(target=foo)\n",
    "\n",
    "t.start()\n",
    "logging.debug('Started')\n",
    "#t.join()\n",
    "logging.debug('Joined ..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows that the threads indeed make the work appear to be done concurrently: the total time lapsed is just slightly more than the resting time of the longest resting worker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:07:17.495 (Worker-2) n=2, rested 0.33 seconds\n",
      "17:07:17.497 (Worker-1) n=1, rested 0.33 seconds\n",
      "17:07:17.716 (Worker-4) n=4, rested 0.55 seconds\n",
      "17:07:17.967 (Worker-3) n=3, rested 0.8 seconds\n",
      "17:07:18.095 (Worker-0) n=0, rested 0.93 seconds\n",
      "17:07:18.098 (MainThread) Lapsed: 0.9341\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from random import randint\n",
    "import threading\n",
    "\n",
    "def foo(n=0):\n",
    "    rest = randint(30,100) * 0.01\n",
    "    time.sleep(rest)\n",
    "    logging.debug(\"n={}, rested {:3.2} seconds\".format(n, rest))\n",
    "    return rest\n",
    "    \n",
    "t = time.time()\n",
    "workers = [threading.Thread(name=f\"Worker-{i}\", target=foo, args=(i,)) for i in range(5)]\n",
    "for w in workers:\n",
    "    w.start()\n",
    "for w in workers:\n",
    "    w.join()\n",
    "logging.debug(\"Lapsed: {:.4f}\".format( time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we collect the various resting times, i.e. to compute their sum?\n",
    "For this you could use the concurrent.futures module: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:07:25.775 (ThreadPoolExecutor-0_1) n=1, rested 0.38 seconds\n",
      "17:07:25.895 (ThreadPoolExecutor-0_0) n=0, rested 0.5 seconds\n",
      "17:07:25.936 (ThreadPoolExecutor-0_3) n=3, rested 0.54 seconds\n",
      "17:07:26.166 (ThreadPoolExecutor-0_4) n=4, rested 0.77 seconds\n",
      "17:07:26.336 (ThreadPoolExecutor-0_2) n=2, rested 0.94 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures as cf\n",
    "pool = cf.ThreadPoolExecutor(5)\n",
    "futures = (pool.submit(foo, n) for n in range(5))\n",
    "sum(f.result() for f in cf.as_completed(futures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ThreadPoolExecutor of concurrent.futures is convenient, but as always you have additional options. You could for instance add a mutable \"out\" argument to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:07:53.220 (Worker-2) n=2, rested 0.44 seconds\n",
      "17:07:53.380 (Worker-4) n=4, rested 0.6 seconds\n",
      "17:07:53.382 (Worker-1) n=1, rested 0.6 seconds\n",
      "17:07:53.389 (Worker-0) n=0, rested 0.61 seconds\n",
      "17:07:53.394 (Worker-3) n=3, rested 0.61 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.86"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo2(n=0, out=None):\n",
    "    rest = randint(30,100) * 0.01\n",
    "    time.sleep(rest)\n",
    "    logging.debug(\"n={}, rested {:3.2} seconds\".format(n, rest))\n",
    "    out[threading.current_thread()] = rest\n",
    "    return rest\n",
    "    \n",
    "t = time.time()\n",
    "result = {}\n",
    "workers = [threading.Thread(name=f\"Worker-{i}\", target=foo2, args=(i, result)) for i in range(5)]\n",
    "for w in workers:\n",
    "    w.start()\n",
    "for w in workers:\n",
    "    \n",
    "    w.join()\n",
    "sum(result.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could write a little decorator that generalizes this solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:08:21.384 (Worker-2) n=2, rested 0.38 seconds\n",
      "17:08:21.596 (Worker-4) n=4, rested 0.59 seconds\n",
      "17:08:21.705 (Worker-0) n=0, rested 0.7 seconds\n",
      "17:08:21.884 (Worker-1) n=1, rested 0.88 seconds\n",
      "17:08:21.995 (Worker-3) n=3, rested 0.99 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import wraps\n",
    "def save(out):\n",
    "    def wrapper(fun):\n",
    "        @wraps(fun)\n",
    "        def wrapped(*args, **kwargs):\n",
    "            out.append(fun(*args, **kwargs))\n",
    "        return wrapped\n",
    "    return wrapper\n",
    "\n",
    "result = []\n",
    "@save(result)\n",
    "def foo(n=0):\n",
    "    rest = randint(30,100) * 0.01\n",
    "    time.sleep(rest)\n",
    "    logging.debug(\"n={}, rested {:3.2} seconds\".format(n, rest))\n",
    "    return rest\n",
    "workers = [threading.Thread(name=f\"Worker-{i}\", target=foo, args=(i,)) for i in range(5)]\n",
    "for w in workers:\n",
    "    w.start()\n",
    "for w in workers:\n",
    "    w.join()\n",
    "sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works because list.append is **threadsafe**: an append in one thread cannot be interrupted by actions on the list in other threads. This is not true for other actions on lists, or on other container. As we will see, a better solution is to always use threadsafe *containers* such as a Queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python can guarantee list.append to be threadsafe because it uses a lock, the General Interpreter Lock to ensure that calls such as append cannot be interrupted by other threads. This GIL however, works on a very fine level, which means that even basic statements such as augmented assignment (which actually consist of the application of some operation followed by an assignment) are NOT threadsafe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:08:25.796 (MainThread) Total: 2442714 [should be: 5000000]- time: 0.5901\n"
     ]
    }
   ],
   "source": [
    "import random, time\n",
    "repeats = 10**6  # try different numbers\n",
    "record = {'total':0}\n",
    "def foo(n=0):\n",
    "    #logging.debug('Entering foo' , n)\n",
    "    for i in range(10**6):\n",
    "        record['total'] += 1\n",
    "    \n",
    "t = time.time()\n",
    "workers = [threading.Thread(name=f\"Worker-{i}\", target=foo, args=(i,)) \n",
    "                for i  in range(5,0,-1)]\n",
    "for w in workers:\n",
    "    #time.sleep(0.1) # try different delays\n",
    "    w.start()\n",
    "for w in workers:\n",
    "    w.join()\n",
    "logging.debug(\"Total: {} [should be: {}]- time: {:.4f}\".format(record['total'], repeats * len(workers), time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As you can see, the totals are way off (and the print statements may also be interrupted ...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locks\n",
    "To deal with this, we need to use our own lock to avoid interruption of the += statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:08:35.372 (MainThread) Total: 5000000 - time: 0.5950\n"
     ]
    }
   ],
   "source": [
    "#%%timeit \n",
    "import random\n",
    "lock = threading.RLock()\n",
    "record = {'total':0}\n",
    "def foo(n=0):\n",
    "    #logging.debug('Entering foo' , n)  \n",
    "    with lock:      # a lock needs to be acquired before the thread can proceed; it has to be released \n",
    "                    # to give other threads a chance; the with lock ... statement handles this in its entry and exit\n",
    "        for i in range(10**6):\n",
    "            record['total'] += 1\n",
    "t = time.time()\n",
    "workers = [threading.Thread(name=f\"Worker-{i}\", target=foo, args=(i,)) \n",
    "                for i  in range(5,0,-1)]\n",
    "for w in workers:\n",
    "    w.start()\n",
    "for w in workers:\n",
    "    w.join()\n",
    "logging.debug(\"Total: {} - time: {:.4f}\".format(record['total'], time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By putting the lock outside the loop, we are basically forcing the threads to run one after the other. We could also put the lock on the individual assignment. That will dramatically increase the amount of thread switching and give us an idea of the cost of that switching. You can also compare this to the single threaded solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 ms ± 32.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "record = {'total':0}\n",
    "for _ in range(5): \n",
    "    for _ in range(10**6): \n",
    "        record['total'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditions\n",
    "Conditions are locks with some additional methods. Once acquired a process can decide to wait (i.e. release the lock but block until it gets notified from some other thread (or its timeout expires):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:09:34.276 (c2) got 1\n",
      "17:09:34.410 (c2) got 2\n",
      "17:09:34.543 (c2) got 3\n",
      "17:09:34.676 (c2) got 4\n",
      "17:09:34.809 (c2) got 5\n",
      "17:09:34.941 (c2) got 6\n",
      "17:09:35.073 (c2) got 7\n",
      "17:09:35.206 (c2) got 8\n",
      "17:09:35.339 (c2) got 9\n",
      "17:09:35.472 (c2) got 10\n",
      "17:09:35.605 (c1) got 1\n",
      "17:09:35.740 (c1) got 2\n",
      "17:09:35.872 (c1) got 3\n",
      "17:09:36.005 (c1) got 4\n",
      "17:09:36.139 (c1) got 5\n",
      "17:09:36.271 (c1) got 6\n",
      "17:09:36.404 (c1) got 7\n",
      "17:09:36.537 (c1) got 8\n",
      "17:09:36.670 (c1) got 9\n",
      "17:09:36.803 (c1) got 10\n",
      "17:09:37.836 (p) halted at 21\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Condition, current_thread\n",
    "cond = Condition()\n",
    "bucket = set()\n",
    "\n",
    "def consumer(bucket):\n",
    "    catches = 0\n",
    "    while catches < 10:\n",
    "        with cond:\n",
    "            cond.wait()\n",
    "            if bucket:\n",
    "                catches += 1\n",
    "                bucket.pop()\n",
    "                time.sleep(0.1)\n",
    "                logging.debug('got {}'.format(catches))\n",
    "            cond.notify()\n",
    "\n",
    "def producer(bucket):\n",
    "    n = 0\n",
    "    while True:\n",
    "        with cond:\n",
    "            time.sleep(0.03)\n",
    "            n += 1\n",
    "            bucket.add(object())\n",
    "            cond.notifyAll()\n",
    "            cond.wait(1)\n",
    "            if bucket:\n",
    "                logging.debug(f\"halted at {n}\")\n",
    "                break\n",
    "\n",
    "c1 = Thread(name='c1', target=consumer, args=(bucket,))\n",
    "c2 = Thread(name='c2', target=consumer, args=(bucket,))\n",
    "p = Thread(name='p', target=producer, args=(bucket,))\n",
    "c2.start()\n",
    "c1.start()\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways to improve the above code, e.g. by passing the condition as an argument to the various threads, instead of using a global one. In general the threadsafe Queue offered in the queue module is a preferred way for dealing with coordination and data sharing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:09:57.862 (c1) caught: 1\n",
      "17:09:58.465 (c1) caught: 2\n",
      "17:09:58.563 (c2) caught: 1\n",
      "17:09:59.067 (c1) caught: 3\n",
      "17:09:59.180 (p) Finished production ..\n",
      "17:09:59.668 (c1) caught: 4\n",
      "17:09:59.767 (c2) caught: 2\n",
      "17:10:00.269 (c1) caught: 5\n",
      "17:10:00.870 (c1) caught: 6\n",
      "17:10:00.969 (c2) caught: 3\n",
      "17:10:01.472 (c1) caught: 7\n",
      "17:10:02.074 (c1) caught: 8\n",
      "17:10:02.170 (c2) caught: 4\n",
      "17:10:02.675 (c1) caught: 9\n",
      "17:10:03.277 (c1) caught: 10\n",
      "17:10:03.371 (c2) caught: 5\n",
      "17:10:03.879 (c1) caught: 11\n",
      "17:10:04.481 (c1) caught: 12\n",
      "17:10:04.573 (c2) caught: 6\n",
      "17:10:05.082 (c1) caught: 13\n",
      "17:10:05.774 (c2) caught: 7\n",
      "17:10:05.774 (MainThread) Ready\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue, Full\n",
    "\n",
    "queue = Queue()\n",
    "def consumer(queue, t):\n",
    "    catches = 0\n",
    "    while True:\n",
    "        queue.get()\n",
    "        catches += 1\n",
    "        time.sleep(t)\n",
    "        queue.task_done()\n",
    "        logging.debug('caught: {}'.format(catches))\n",
    "\n",
    "def producer(queue, n):\n",
    "    while n > 0:\n",
    "        time.sleep(0.1)\n",
    "        n -= 1\n",
    "        try:\n",
    "            queue.put(object(), timeout=1)\n",
    "        except Full: \n",
    "            logging.debug(f\"halted at {n}\")\n",
    "            break\n",
    "    else:\n",
    "        logging.debug(f\"Finished production ..\")\n",
    "        queue.join()\n",
    "\n",
    "workers = [Thread(name='c'+str(i), target=consumer, args=(queue, i* 0.6)) for i in range(1,3)]\n",
    "p = Thread(name='p', target=producer, args=(queue, 20))\n",
    "p.start()\n",
    "for w in workers:\n",
    "    #w.daemon = True\n",
    "    w.start()\n",
    "p.join()\n",
    "logging.debug('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other synchronizers\n",
    "#### Event\n",
    "Conditions allow a process to wait for some condition and then acquire exclusive access. Events are used ust to wait for some event, when there is no need for exclusive use of resources: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:10:17.037 (block) wait_for_event starting\n",
      "17:10:17.047 (nonblock) wait_for_event_timeout starting\n",
      "17:10:17.048 (MainThread) Pausing before calling Event.set()\n",
      "17:10:17.360 (nonblock) event set: False\n",
      "17:10:17.361 (nonblock) doing other work\n",
      "17:10:17.361 (nonblock) wait_for_event_timeout starting\n",
      "17:10:17.672 (nonblock) event set: False\n",
      "17:10:17.672 (nonblock) doing other work\n",
      "17:10:17.673 (nonblock) wait_for_event_timeout starting\n",
      "17:10:17.987 (nonblock) event set: False\n",
      "17:10:17.988 (nonblock) doing other work\n",
      "17:10:17.988 (nonblock) wait_for_event_timeout starting\n",
      "17:10:18.053 (MainThread) Event is set\n",
      "17:10:18.053 (block) processing event\n",
      "17:10:18.053 (nonblock) event set: True\n",
      "17:10:18.056 (nonblock) processing event\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def wait_for_event(e):\n",
    "    \"\"\"Wait for the event to be set before doing anything\"\"\"\n",
    "    logging.debug('wait_for_event starting')\n",
    "    event_is_set = e.wait()\n",
    "    logging.debug('processing event')\n",
    "\n",
    "def wait_for_event_timeout(e, t):\n",
    "    \"\"\"Wait t seconds and then timeout\"\"\"\n",
    "    while not e.is_set():\n",
    "        logging.debug('wait_for_event_timeout starting')\n",
    "        event_is_set = e.wait(t)\n",
    "        logging.debug('event set: %s', event_is_set)\n",
    "        if event_is_set:\n",
    "            logging.debug('processing event')\n",
    "        else:\n",
    "            logging.debug('doing other work')\n",
    "\n",
    "e = threading.Event()\n",
    "threading.Thread(name='block', target=wait_for_event, args=(e,)).start()\n",
    "threading.Thread(name='nonblock', target=wait_for_event_timeout, args=(e, 0.3)).start()\n",
    "\n",
    "logging.debug('Pausing before calling Event.set()')\n",
    "time.sleep(1.0)\n",
    "e.set()\n",
    "logging.debug('Event is set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Barrier\n",
    "Allows process to wait until enough others have reported themselves to be ready (by also waiting on that same barrier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:10:22.034 (MainThread) worker-0 starting\n",
      "17:10:22.036 (worker-0) waiting for barrier with 0 others\n",
      "17:10:22.138 (MainThread) worker-1 starting\n",
      "17:10:22.139 (worker-1) waiting for barrier with 1 others\n",
      "17:10:22.242 (MainThread) worker-2 starting\n",
      "17:10:22.243 (worker-2) waiting for barrier with 2 others\n",
      "17:10:22.246 (worker-2) after barrier 2\n",
      "17:10:22.246 (worker-0) after barrier 0\n",
      "17:10:22.246 (worker-1) after barrier 1\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def worker(barrier):\n",
    "    logging.debug(f'waiting for barrier with {barrier.n_waiting} others')\n",
    "    try:\n",
    "        worker_id = barrier.wait()\n",
    "    except threading.BrokenBarrierError:\n",
    "        logging.debug('aborting')\n",
    "    else:\n",
    "        logging.debug(f'after barrier {worker_id}')\n",
    "\n",
    "barrier = threading.Barrier(3)\n",
    "\n",
    "threads = [threading.Thread(name='worker-%s' % i, target=worker, args=(barrier,))\n",
    "    for i in range(3)]\n",
    "\n",
    "for t in threads:\n",
    "    logging.debug(f'{t.name} starting')\n",
    "    t.start()\n",
    "    time.sleep(0.1)\n",
    "\n",
    "n = len([t for t in threading.enumerate() if t is not threading.main_thread()])\n",
    "\n",
    "if n < barrier.parties:\n",
    "    barrier.abort()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semaphore\n",
    "A limited set of locks: waiting thread is unblocked whenever a lock comes available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:10:27.035 (Thread-1) Waiting to join the pool\n",
      "17:10:27.038 (Thread-2) Waiting to join the pool\n",
      "17:10:27.039 (Thread-3) Waiting to join the pool\n",
      "17:10:27.039 (Thread-4) Waiting to join the pool\n",
      "17:10:27.039 (Thread-1) Starting: Thread-1\n",
      "17:10:27.043 (Thread-2) Starting: Thread-2\n",
      "17:10:27.152 (Thread-1) Stopping: Thread-1\n",
      "17:10:27.153 (Thread-2) Stopping: Thread-2\n",
      "17:10:27.153 (Thread-3) Starting: Thread-3\n",
      "17:10:27.154 (Thread-4) Starting: Thread-4\n",
      "17:10:27.256 (Thread-4) Stopping: Thread-4\n",
      "17:10:27.256 (Thread-3) Stopping: Thread-3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from threading import Thread\n",
    "\n",
    "def worker(s):\n",
    "    logging.debug('Waiting to join the pool')\n",
    "    with s:\n",
    "        name = threading.current_thread().getName()\n",
    "        logging.debug(f'Starting: {name}')\n",
    "        time.sleep(0.1)\n",
    "        logging.debug(f'Stopping: {name}')\n",
    "\n",
    "s = threading.Semaphore(2)\n",
    "workers = [Thread(name=f'Thread-{i}', target=worker, args=(s,)) for i in range(1,5)]\n",
    "for w in workers: w.start()\n",
    "for w in workers: w.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threadsafe storage\n",
    "The threading.local class provides one way to reuse global names in a thread without affecting other threads. This is mainly useful if you do not want to adapt single-threaded code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:11:38.463 (Thread-9) 88\n",
      "17:11:38.467 (MainThread) 42\n",
      "17:11:38.467 (MainThread) 88\n",
      "17:11:38.468 (MainThread) 88\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "loc = threading.local()\n",
    "loc.foo = 42\n",
    "def targ():\n",
    "    loc.foo = 88\n",
    "    logging.debug(loc.foo)\n",
    "t = threading.Thread(target=targ)\n",
    "t.start()\n",
    "t.join()\n",
    "logging.debug(loc.foo)\n",
    "targ()\n",
    "logging.debug(loc.foo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contextvars\n",
    "A more general solution for asynchronous processes, including coroutines running in a single thread, is the use of Context Variables. However, dote that the copy will be shallow, so changes to mutable objects will not be restricted to the copied version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:12:48.642 (MainThread) {'x': 'spam'}, 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'x': 'ham'}, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from contextvars import ContextVar, copy_context\n",
    "x = ContextVar('x')\n",
    "y = ContextVar('y')\n",
    "x.set({'x':'spam'})\n",
    "y.set(4)\n",
    "def main(): \n",
    "    logging.debug(f\"{x.get()}, {y.get()}\")\n",
    "    x.get()['x'] = 'ham' \n",
    "    y.set(9)\n",
    "ctx = copy_context() \n",
    "ctx.run(main)\n",
    "x.get(), y.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "The following is an example of a simple producer-consumer pattern using multiprocessing. You cannot run this directly from the cell: save it as a Python module, say `multiprog.py` and run it like: `python -m multiprog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:24:19.619 (MainThread) Creating 16 consumers\n",
      "17:24:19.625 (MainThread) <Consumer(Consumer-1, initial)>\n",
      "17:24:19.632 (MainThread) <Consumer(Consumer-2, initial)>\n",
      "17:24:19.636 (MainThread) <Consumer(Consumer-3, initial)>\n",
      "17:24:19.641 (MainThread) <Consumer(Consumer-4, initial)>\n",
      "17:24:19.645 (MainThread) <Consumer(Consumer-5, initial)>\n",
      "17:24:19.650 (MainThread) <Consumer(Consumer-6, initial)>\n",
      "17:24:19.656 (MainThread) <Consumer(Consumer-7, initial)>\n",
      "17:24:19.662 (MainThread) <Consumer(Consumer-8, initial)>\n",
      "17:24:19.666 (MainThread) <Consumer(Consumer-9, initial)>\n",
      "17:24:19.670 (MainThread) <Consumer(Consumer-10, initial)>\n",
      "17:24:19.674 (MainThread) <Consumer(Consumer-11, initial)>\n",
      "17:24:19.679 (MainThread) <Consumer(Consumer-12, initial)>\n",
      "17:24:19.684 (MainThread) <Consumer(Consumer-13, initial)>\n",
      "17:24:19.689 (MainThread) <Consumer(Consumer-14, initial)>\n",
      "17:24:19.694 (MainThread) <Consumer(Consumer-15, initial)>\n",
      "17:24:19.699 (MainThread) <Consumer(Consumer-16, initial)>\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time, logging   \n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    format='%(asctime)s.%(msecs)03d %(message)s')\n",
    "\n",
    "class Consumer(multiprocessing.Process):\n",
    "\n",
    "    def __init__(self, task_queue, result_queue):\n",
    "        multiprocessing.Process.__init__(self)\n",
    "        self.task_queue = task_queue\n",
    "        self.result_queue = result_queue\n",
    "\n",
    "    def run(self):\n",
    "        proc_name = self.name\n",
    "        while True:\n",
    "            logging.debug(f'{proc_name} awaiting next task ...')\n",
    "            next_task = self.task_queue.get()\n",
    "            if next_task is None:\n",
    "                # Poison pill means shutdown\n",
    "                logging.debug('Exiting {}'.format(proc_name))\n",
    "                self.task_queue.task_done()\n",
    "                break\n",
    "            logging.debug('New task for {}: {}'.format(proc_name, next_task))\n",
    "            answer = next_task()\n",
    "            self.task_queue.task_done()\n",
    "            self.result_queue.put(answer)\n",
    "\n",
    "class Task:\n",
    "\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self):\n",
    "        time.sleep(0.1)  # pretend to take time to do the work\n",
    "        return '{self.a} * {self.b} = {product}'.format(self=self, product=self.a * self.b)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '{self.a} * {self.b}'.format(self=self)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Establish communication queues\n",
    "    tasks = multiprocessing.JoinableQueue()\n",
    "    results = multiprocessing.Queue()\n",
    "    \n",
    "    # Start consumers\n",
    "    num_consumers = multiprocessing.cpu_count() * 2\n",
    "    logging.debug('Creating {} consumers'.format(num_consumers))\n",
    "    consumers = [Consumer(tasks, results) for i in range(num_consumers)]\n",
    "    \n",
    "    for w in consumers:\n",
    "        w.start()\n",
    "    \n",
    "    # Enqueue jobs\n",
    "    num_jobs = 20\n",
    "    for i in range(num_jobs):\n",
    "        tasks.put(Task(i, i))\n",
    "    \n",
    "    # Add a poison pill for each consumer\n",
    "    for i in range(num_consumers):\n",
    "        tasks.put(None)\n",
    "    \n",
    "    # Wait for all of the tasks to finish\n",
    "    tasks.join()\n",
    "    \n",
    "    # Start printing results\n",
    "    for _ in range(num_jobs):\n",
    "        result = results.get()\n",
    "        logging.debug(f'Result: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `concurrent.futures.ProcessPoolExecutor` is easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf\n",
    "import multiprocessing as mp\n",
    "import time, logging   \n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    format='%(asctime)s.%(msecs)03d %(message)s',\n",
    ")\n",
    "\n",
    "def consumer(task):\n",
    "    name = mp.current_process().name\n",
    "    logging.debug('New task for {}: {}'.format(name, task))\n",
    "    return task()\n",
    "\n",
    "class Task:\n",
    "\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self):\n",
    "        time.sleep(0.1)  # pretend to take time to do the work\n",
    "        return '{self.a} * {self.b} = {product}'.format(self=self, product=self.a * self.b)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '{self.a} * {self.b}'.format(self=self)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Establish communication queues\n",
    "    tasks = mp.JoinableQueue()\n",
    "    \n",
    "    # Start consumers\n",
    "    executor = cf.ProcessPoolExecutor()\n",
    "    logging.debug('Creating {} consumers'.format(executor._max_workers))\n",
    "    num_jobs = 20\n",
    "    futures = [executor.submit(consumer, Task(i, i)) for i in range(num_jobs)]\n",
    "    # Wait for all of the tasks to finish\n",
    "    \n",
    "    for f in cf.as_completed(futures):\n",
    "        logging.debug(f'Result: {f.result()}')\n",
    "\n",
    "   # or wait for all futures to be ready:      \n",
    "    ok, failed = cf.wait(futures)\n",
    "    print(*sorted(f.result() for f in ok), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous processing using coroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input can be 'injected' into generators as yield statements are actually expressions returning whatever value `val` was provided to the `send(val)` method (which also moves process to next `yield`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1 2 9\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    yield 1\n",
    "    val = yield 2\n",
    "    print(val)\n",
    "    yield val\n",
    "g = gen()\n",
    "print(\n",
    "    g.send(None), # returns 1, blocked at the 'yield 1' expression \n",
    "    g.send(None), # sets the 'yield 1' expression to None, moves to next yield and returns 2\n",
    "    g.send(9)    # sets the 'yield 2' expression to 9, binds val to its value, moves to next yield and returns val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        val = yield n\n",
    "        if val: n = val\n",
    "        n -= 1\n",
    "c = countdown(5)\n",
    "next(c), c.send(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two other generator methods complete the groundswork for a coroutine: the `close` method and the `throw` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-26473b4526cf>\u001b[0m in \u001b[0;36mgen\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32myield\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-26473b4526cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    yield 1\n",
    "    val = yield 2\n",
    "    print(val)\n",
    "    yield val\n",
    "g = gen()\n",
    "print(next(g))\n",
    "g.throw(StopIteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1366ebfc069b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    yield 1\n",
    "    val = yield 2\n",
    "    print(val)\n",
    "    yield val\n",
    "g = gen()\n",
    "print(next(g))\n",
    "g.close()\n",
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Generator exit\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    try:\n",
    "        yield 1\n",
    "        val = yield 2\n",
    "        print(val)\n",
    "        yield val\n",
    "    except GeneratorExit:\n",
    "        print(\"Generator exit\")\n",
    "g = gen()\n",
    "print(next(g))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Attribute error\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-eff19c6fd07b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    try:\n",
    "        yield 1\n",
    "        val = yield 2\n",
    "        print(val)\n",
    "        yield val\n",
    "    except AttributeError:\n",
    "        print(\"Attribute error\")\n",
    "g = gen()\n",
    "print(next(g))\n",
    "g.throw(AttributeError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This small taxi sumulator shows the use of generators  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi: 0  Event(time=0, proc=0, action='leave garage')\n",
      "taxi: 0  Event(time=2, proc=0, action='pick up passenger')\n",
      "taxi: 1     Event(time=5, proc=1, action='leave garage')\n",
      "taxi: 1     Event(time=10, proc=1, action='pick up passenger')\n",
      "taxi: 2        Event(time=10, proc=2, action='leave garage')\n",
      "taxi: 2        Event(time=12, proc=2, action='pick up passenger')\n",
      "taxi: 1     Event(time=15, proc=1, action='drop off passenger')\n",
      "taxi: 2        Event(time=18, proc=2, action='drop off passenger')\n",
      "taxi: 2        Event(time=21, proc=2, action='pick up passenger')\n",
      "taxi: 1     Event(time=22, proc=1, action='pick up passenger')\n",
      "taxi: 2        Event(time=35, proc=2, action='drop off passenger')\n",
      "taxi: 2        Event(time=39, proc=2, action='pick up passenger')\n",
      "taxi: 1     Event(time=46, proc=1, action='drop off passenger')\n",
      "taxi: 1     Event(time=55, proc=1, action='pick up passenger')\n",
      "taxi: 0  Event(time=63, proc=0, action='drop off passenger')\n",
      "taxi: 1     Event(time=75, proc=1, action='drop off passenger')\n",
      "taxi: 0  Event(time=76, proc=0, action='pick up passenger')\n",
      "taxi: 0  Event(time=81, proc=0, action='drop off passenger')\n",
      "taxi: 1     Event(time=82, proc=1, action='pick up passenger')\n",
      "taxi: 0  Event(time=91, proc=0, action='going home')\n",
      "taxi: 2        Event(time=111, proc=2, action='drop off passenger')\n",
      "taxi: 2        Event(time=115, proc=2, action='pick up passenger')\n",
      "taxi: 2        Event(time=118, proc=2, action='drop off passenger')\n",
      "taxi: 1     Event(time=120, proc=1, action='drop off passenger')\n",
      "taxi: 2        Event(time=120, proc=2, action='pick up passenger')\n",
      "taxi: 1     Event(time=127, proc=1, action='going home')\n",
      "taxi: 2        Event(time=132, proc=2, action='drop off passenger')\n",
      "taxi: 2        Event(time=133, proc=2, action='pick up passenger')\n",
      "taxi: 2        Event(time=146, proc=2, action='drop off passenger')\n",
      "taxi: 2        Event(time=152, proc=2, action='going home')\n",
      "*** end of events ***\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import collections\n",
    "import queue\n",
    "\n",
    "DEFAULT_NUMBER_OF_TAXIS = 3\n",
    "DEFAULT_END_TIME = 180\n",
    "SEARCH_DURATION = 5\n",
    "TRIP_DURATION = 20\n",
    "DEPARTURE_INTERVAL = 5\n",
    "\n",
    "Event = collections.namedtuple('Event', 'time proc action')\n",
    "\n",
    "def taxi_process(ident, trips, start_time=0):  \n",
    "    \"\"\"Yield to simulator issuing event at each state change\"\"\"\n",
    "    time = yield Event(start_time, ident, 'leave garage')  \n",
    "    for i in range(trips):  \n",
    "        time = yield Event(time, ident, 'pick up passenger')  \n",
    "        time = yield Event(time, ident, 'drop off passenger')  \n",
    "    yield Event(time, ident, 'going home')  \n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, procs_map):\n",
    "        self.events = queue.PriorityQueue()\n",
    "        self.procs = dict(procs_map)\n",
    "\n",
    "    def run(self, end_time):  # <1>\n",
    "        \"\"\"Schedule and display events until time is up\"\"\"\n",
    "        # schedule the first event for each cab\n",
    "        for _, proc in sorted(self.procs.items()):  \n",
    "            first_event = next(proc) \n",
    "            self.events.put(first_event)  \n",
    "\n",
    "        # main loop of the simulation\n",
    "        sim_time = 0\n",
    "        while sim_time < end_time:\n",
    "            if self.events.empty():\n",
    "                print('*** end of events ***')\n",
    "                break\n",
    "\n",
    "            current_event = self.events.get()  \n",
    "            sim_time, proc_id, previous_action = current_event  \n",
    "            print('taxi:', proc_id, proc_id * '   ', current_event)  \n",
    "            active_proc = self.procs[proc_id]  \n",
    "            next_time = sim_time + compute_duration(previous_action) \n",
    "            try:\n",
    "                next_event = active_proc.send(next_time)  \n",
    "            except StopIteration:\n",
    "                del self.procs[proc_id]  \n",
    "            else:\n",
    "                self.events.put(next_event)\n",
    "        else:\n",
    "            msg = '*** end of simulation time: {} events pending ***'\n",
    "            print(msg.format(self.events.qsize()))\n",
    "\n",
    "def compute_duration(previous_action):\n",
    "    \"\"\"Compute action duration using exponential distribution\"\"\"\n",
    "    if previous_action in ['leave garage', 'drop off passenger']:\n",
    "        # new state is prowling\n",
    "        interval = SEARCH_DURATION\n",
    "    elif previous_action == 'pick up passenger':\n",
    "        # new state is trip\n",
    "        interval = TRIP_DURATION\n",
    "    elif previous_action == 'going home':\n",
    "        interval = 1\n",
    "    else:\n",
    "        raise ValueError('Unknown previous_action: %s' % previous_action)\n",
    "    return int(random.expovariate(1/interval)) + 1\n",
    "\n",
    "def main(end_time=DEFAULT_END_TIME, num_taxis=DEFAULT_NUMBER_OF_TAXIS,\n",
    "         seed=None):\n",
    "    \"\"\"Initialize random generator, build procs and run simulation\"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)  # get reproducible results\n",
    "\n",
    "    taxis = {i: taxi_process(i, (i+1)*2, i*DEPARTURE_INTERVAL)\n",
    "             for i in range(num_taxis)}\n",
    "    sim = Simulator(taxis)\n",
    "    sim.run(end_time)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other new keyword; `yield from`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chain(*iterables):\n",
    "    for it in iterables:\n",
    "        for i in it:\n",
    "            yield i\n",
    "list(chain(range(5), range(9,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "More convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chain(*iterables):\n",
    "    for it in iterables:\n",
    "        yield from it\n",
    "list(chain(range(5), range(9,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treegen(n):\n",
    "    while n > 0:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two new keywords to specify coroutine functions: `async` and `await`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello ...\n",
      "Hello ...\n",
      "Hello ...\n",
      "Hello ...\n",
      "Hello ...\n",
      "... Jan!\n",
      "... Klaas!\n",
      "... Klarien!\n",
      "... Piet!\n",
      "... Mien!\n"
     ]
    }
   ],
   "source": [
    "import asyncio \n",
    "async def coro(name='world'): \n",
    "    print('Hello ...') \n",
    "    await asyncio.sleep(0.5) \n",
    "    print(f'... {name}!')  \n",
    "# asyncio.run(coro()) if no loop is running yet; in notebook there is one running already, so use create_task\n",
    "futures = [asyncio.create_task(coro(name)) for name in \"Jan Piet Klaas Mien Klarien\".split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 1) total time remains almost constant when adding names, 2) the order in which tasks finish is undetermined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronous processing is particularly useful in dealing with IO. To use coroutines it is important to use libraries that have themselves also been set up as coroutines, otherwise you will still run into blocking IO calls: any such routines have to yield when running into potential blocking calls. The `aiohttp` module is such a \"coroutine-ready\"  module: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing other stuff while waiting for pages to come in ...\n",
      "--------------------------------------------------------------------------------\n",
      "              A   M I N D   F O R E V E R   V O Y A G I N G \n",
      "                                 (Infocom)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "from: the Asimov collection\n",
      "                                 BALLYHOO\n",
      "                                 (Infocom)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "from: the Asimov collection\n",
      "                    T H E   B A R D ' S   T A L E   I \n",
      "                          (Tales Of The Unknown)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "\n",
    "async def print_preview(url):\n",
    "    # connect to the server\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # create get request\n",
    "        async with session.get(url) as response:\n",
    "            # wait for response\n",
    "            response = await response.text()\n",
    "            # print first 3 not empty lines\n",
    "            lines = list(filter(lambda x: len(x) > 0, response.split('\\n')))\n",
    "            print('-'*80)\n",
    "            for line in lines[:3]:\n",
    "                print(line)\n",
    "            print()\n",
    "\n",
    "def print_pages():\n",
    "    pages = [\n",
    "        'http://textfiles.com/adventure/amforever.txt',\n",
    "        'http://textfiles.com/adventure/ballyhoo.txt',\n",
    "        'http://textfiles.com/adventure/bardstale.txt',\n",
    "    ]\n",
    "    loop = asyncio.new_event_loop()\n",
    "    for page in pages:\n",
    "        asyncio.create_task(print_preview(page))\n",
    "\n",
    "print_pages()\n",
    "print(\"Doing other stuff while waiting for pages to come in ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another example, running two tasks and cancelling one when the other is done. Note the `async for` loop in `print_prime`: you need an async version of the for loop when the generator is not a regular generator but an asynchronous one like `prime_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending coro=<main() running at <ipython-input-58-010b8608ef9f>:38>>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 new email\n",
      "new prime number found: 1\n",
      "new prime number found: 2\n",
      "new prime number found: 3\n",
      "new prime number found: 5\n",
      "new prime number found: 7\n",
      "new prime number found: 11\n",
      "new prime number found: 13\n",
      "7 new email\n",
      "new prime number found: 17\n",
      "new prime number found: 19\n",
      "8 new email\n",
      "new prime number found: 23\n",
      "new prime number found: 29\n",
      "17 new email\n",
      "new prime number found: 31\n",
      "17 new email\n",
      "new prime number found: 37\n",
      "17 new email\n",
      "new prime number found: 41\n",
      "14 new email\n",
      "new prime number found: 43\n",
      "Prime generator finished ...\n",
      "Cancelling email checks ..\n"
     ]
    }
   ],
   "source": [
    "import random, asyncio\n",
    "\n",
    "async def is_prime(n):\n",
    "    if n < 2:\n",
    "        return True\n",
    "    for i in range(2, n):\n",
    "        # allow event_loop to run other coroutine\n",
    "        await asyncio.sleep(0.01)\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "async def prime_generator(n_prime):\n",
    "    counter = 0\n",
    "    n = 0\n",
    "    while counter < n_prime:\n",
    "        n += 1\n",
    "        # wait for is_prime to finish\n",
    "        prime = await is_prime(n)\n",
    "        if prime:\n",
    "            yield n\n",
    "            counter += 1\n",
    "\n",
    "async def check_email():\n",
    "    while True:\n",
    "        try:\n",
    "            n = random.randrange(1,18)\n",
    "            print(f'{n} new email')\n",
    "            await asyncio.sleep(0.5)\n",
    "        except asyncio.CancelledError:\n",
    "            print(\"Cancelling email checks ..\")\n",
    "            break\n",
    "\n",
    "async def print_prime(n):\n",
    "    async for prime in prime_generator(n):\n",
    "        print('new prime number found:', prime)\n",
    "\n",
    "async def main():\n",
    "    email = asyncio.create_task(check_email())\n",
    "    prime = asyncio.create_task(print_prime(15))\n",
    "    await asyncio.wait({prime})\n",
    "    print ('Prime generator finished ...')\n",
    "    email.cancel()\n",
    "\n",
    "asyncio.create_task(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
